{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Разреженные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Нам понадобятся пакеты nltk и spacy (на самом деле нет). Можете уже начать их устанавливать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import scipy\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Примеры источников разреженных признаков:\n",
    "* категориальные признаки \n",
    "* текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Категориальные признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Рассмотрим таблицу [```winemag.csv```](https://yadi.sk/d/bi2cwBBO_y6cCA), которая содержит описания вин:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>taster_name</th>\n",
       "      <th>taster_twitter_handle</th>\n",
       "      <th>title</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Italy</td>\n",
       "      <td>Aromas include tropical fruit, broom, brimston...</td>\n",
       "      <td>Vulkà Bianco</td>\n",
       "      <td>87</td>\n",
       "      <td></td>\n",
       "      <td>Sicily &amp; Sardinia</td>\n",
       "      <td>Etna</td>\n",
       "      <td></td>\n",
       "      <td>Kerin O’Keefe</td>\n",
       "      <td>@kerinokeefe</td>\n",
       "      <td>Nicosia 2013 Vulkà Bianco  (Etna)</td>\n",
       "      <td>White Blend</td>\n",
       "      <td>Nicosia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>This is ripe and fruity, a wine that is smooth...</td>\n",
       "      <td>Avidagos</td>\n",
       "      <td>87</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Douro</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Roger Voss</td>\n",
       "      <td>@vossroger</td>\n",
       "      <td>Quinta dos Avidagos 2011 Avidagos Red (Douro)</td>\n",
       "      <td>Portuguese Red</td>\n",
       "      <td>Quinta dos Avidagos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>Tart and snappy, the flavors of lime flesh and...</td>\n",
       "      <td></td>\n",
       "      <td>87</td>\n",
       "      <td>14.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Rainstorm 2013 Pinot Gris (Willamette Valley)</td>\n",
       "      <td>Pinot Gris</td>\n",
       "      <td>Rainstorm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>Pineapple rind, lemon pith and orange blossom ...</td>\n",
       "      <td>Reserve Late Harvest</td>\n",
       "      <td>87</td>\n",
       "      <td>13.0</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>Lake Michigan Shore</td>\n",
       "      <td></td>\n",
       "      <td>Alexander Peartree</td>\n",
       "      <td></td>\n",
       "      <td>St. Julian 2013 Reserve Late Harvest Riesling ...</td>\n",
       "      <td>Riesling</td>\n",
       "      <td>St. Julian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>Much like the regular bottling from 2012, this...</td>\n",
       "      <td>Vintner's Reserve Wild Child Block</td>\n",
       "      <td>87</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Paul Gregutt</td>\n",
       "      <td>@paulgwine</td>\n",
       "      <td>Sweet Cheeks 2012 Vintner's Reserve Wild Child...</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Sweet Cheeks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    country                                        description  \\\n",
       "0     Italy  Aromas include tropical fruit, broom, brimston...   \n",
       "1  Portugal  This is ripe and fruity, a wine that is smooth...   \n",
       "2        US  Tart and snappy, the flavors of lime flesh and...   \n",
       "3        US  Pineapple rind, lemon pith and orange blossom ...   \n",
       "4        US  Much like the regular bottling from 2012, this...   \n",
       "\n",
       "                          designation  points price           province  \\\n",
       "0                        Vulkà Bianco      87        Sicily & Sardinia   \n",
       "1                            Avidagos      87  15.0              Douro   \n",
       "2                                          87  14.0             Oregon   \n",
       "3                Reserve Late Harvest      87  13.0           Michigan   \n",
       "4  Vintner's Reserve Wild Child Block      87  65.0             Oregon   \n",
       "\n",
       "              region_1           region_2         taster_name  \\\n",
       "0                 Etna                          Kerin O’Keefe   \n",
       "1                                                  Roger Voss   \n",
       "2    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "3  Lake Michigan Shore                     Alexander Peartree   \n",
       "4    Willamette Valley  Willamette Valley        Paul Gregutt   \n",
       "\n",
       "  taster_twitter_handle                                              title  \\\n",
       "0          @kerinokeefe                  Nicosia 2013 Vulkà Bianco  (Etna)   \n",
       "1            @vossroger      Quinta dos Avidagos 2011 Avidagos Red (Douro)   \n",
       "2           @paulgwine       Rainstorm 2013 Pinot Gris (Willamette Valley)   \n",
       "3                        St. Julian 2013 Reserve Late Harvest Riesling ...   \n",
       "4           @paulgwine   Sweet Cheeks 2012 Vintner's Reserve Wild Child...   \n",
       "\n",
       "          variety               winery  \n",
       "0     White Blend              Nicosia  \n",
       "1  Portuguese Red  Quinta dos Avidagos  \n",
       "2      Pinot Gris            Rainstorm  \n",
       "3        Riesling           St. Julian  \n",
       "4      Pinot Noir         Sweet Cheeks  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('winemag.csv', index_col=0, na_filter=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В таблице 13 столбцов с признаками. Какие из них являются категориальными? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Во-первых, обычно это столбцы содержащие текстовые значения. Исключением могут быть, например, некоторые идентификаторы (например, цифровой код региона). Следовательно, в качестве кандидатов остаются: ```country```, ```description```, ```designation```, ```province```, ```region_1```, ```region_2```, ```taster_name```, ```taster_twitter_handle```, ```title```, ```variety``` и ```winery```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Во-вторых, столбцы с небольшим числом уникальных значений:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country                      44\n",
       "description              119955\n",
       "designation               37980\n",
       "points                       21\n",
       "price                       391\n",
       "province                    426\n",
       "region_1                   1230\n",
       "region_2                     18\n",
       "taster_name                  20\n",
       "taster_twitter_handle        16\n",
       "title                    118840\n",
       "variety                     708\n",
       "winery                    16757\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Итак, например страна-производитель является категориальным признаком."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Один из самых простых способов кодирования является **one-hot-кодирование**: для кодируемого категориального признака создаются $N$ новых признаков, где $N$ - число категорий. Каждый $i$-й новый признак - бинарный характеристический признак $i$-й категории."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Воспользуемся [LabelEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) (превращает категории в числа) и [OneHotEncoder](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) (превращает числа в векторы) для преобразования названий стран в one-hot-вектор:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countries = data.country\n",
    "countries = LabelEncoder().fit_transform(countries)\n",
    "countries = OneHotEncoder(categories='auto').fit_transform(countries[:, np.newaxis])\n",
    "\n",
    "type(countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Разреженные матрицы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "После кодирования мы получили разреженную матрицу признаков. Существует много типов разреженных матриц, каждый из которых предоставляет разные гарантии на операции.\n",
    "\n",
    "* ```scipy.sparse.coo_matrix```\n",
    "* ```scipy.sparse.csc_matrix```\n",
    "* ```scipy.sparse.csr_matrix```\n",
    "* ```scipy.sparse.bsr_matrix```\n",
    "* ```scipy.sparse.lil_matrix```\n",
    "* ```scipy.sparse.dia_matrix```\n",
    "* ```scipy.sparse.dok_matrix```\n",
    "\n",
    "Подробнее про [устройство разреженых матрицы](http://www.netlib.org/utk/people/JackDongarra/etemplates/node372.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### scipy.sparse.coo_matrix\n",
    "\n",
    "* Используется как хранилище данных\n",
    "* Поддерживает быструю конвертацию в любой формат\n",
    "* Не поддерживает индексацию\n",
    "* Поддерживает ограниченый набор арифметических операций"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### scipy.sparse.csc_matrix\n",
    "\n",
    "* Хранит данные поколоночно\n",
    "* Быстрое получение значений отдельных колонок"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### scipy.sparse.csr_matrix\n",
    "\n",
    "* Хранит данные построчно\n",
    "* Быстрое получение значений отдельных строк"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### scipy.sparse.bsr_matrix\n",
    "\n",
    "* Подходит для разреженных матриц с плотными подматрицами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### scipy.sparse.lil_matrix\n",
    "\n",
    "* Подходит для создания разреженных матриц поэлементно\n",
    "* Для последующих матричных операций лучше сконвертировать в ```csr_matrix``` или ```csc_matrix```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Библиотека ```scipy.sparse``` содержит методы, позволяющие работать с разреженными матрицами. Подробнее про операции с разрежеными матрицами на сайте [scipy](https://docs.scipy.org/doc/scipy/reference/sparse.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Предсказание оценки вин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "В качестве категориальных признаков возьмём: country, province и variety\n",
    "\n",
    "Попробуем предсказать оценку выставленную винам. Оценки в таблице варьируются от 80 до 100."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Решим задачу трехклассовой классификации качества вин. Установим значения целевой переменной в LOW, MID или HIGH в зависимости от оценки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data['quality'] = 'MID'\n",
    "data.loc[data['points'] <= 85, 'quality'] = 'LOW'\n",
    "data.loc[data['points'] > 90, 'quality'] = 'HIGH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MID     74376\n",
       "HIGH    33635\n",
       "LOW     21960\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['country', 'description', 'designation', 'points', 'price', 'province',\n",
       "       'region_1', 'region_2', 'taster_name', 'taster_twitter_handle', 'title',\n",
       "       'variety', 'winery', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "И, собственно, попробуем перебрать все подмножества категориальных признаков и выбрать лучшее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:13: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc69728ed0ed4812a96fd39bdb9a2e18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>0.572148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variety</th>\n",
       "      <td>0.574223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country; variety</th>\n",
       "      <td>0.576858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>province</th>\n",
       "      <td>0.577790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country; province</th>\n",
       "      <td>0.578187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>province; variety</th>\n",
       "      <td>0.579212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country; province; variety</th>\n",
       "      <td>0.584412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Accuracy\n",
       "country                     0.572148\n",
       "variety                     0.574223\n",
       "country; variety            0.576858\n",
       "province                    0.577790\n",
       "country; province           0.578187\n",
       "province; variety           0.579212\n",
       "country; province; variety  0.584412"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data['quality'].values\n",
    "countries = OneHotEncoder(categories='auto').fit_transform(LabelEncoder()\\\n",
    "                                            .fit_transform(data.country)[:, np.newaxis])[:, 1:]\n",
    "provinces = OneHotEncoder(categories='auto').fit_transform(LabelEncoder()\\\n",
    "                                            .fit_transform(data.province)[:, np.newaxis])[:, 1:]\n",
    "varieties = OneHotEncoder(categories='auto').fit_transform(LabelEncoder()\\\n",
    "                                            .fit_transform(data.variety)[:, np.newaxis])[:, 1:]\n",
    "features = [('country', countries), ('province', provinces), ('variety', varieties)]\n",
    "\n",
    "names = []\n",
    "accuracy_scores = []\n",
    "for subset_features in tqdm(list(itertools.chain(*[itertools.combinations(features, n) \n",
    "                                                   for n in range(1, 4)]))):\n",
    "    subset_names, subset_features = zip(*subset_features)\n",
    "    names.append('; '.join(subset_names))\n",
    "    \n",
    "    X = scipy.sparse.hstack(subset_features)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n",
    "    \n",
    "    lr = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000).fit(X_train, Y_train)\n",
    "    Y_pred = lr.predict(X_test)\n",
    "\n",
    "    accuracy_scores.append(accuracy_score(Y_pred, Y_test))\n",
    "\n",
    "pd.DataFrame({'Accuracy':accuracy_scores}, index=names).sort_values('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Извлечение признаков из текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Но у нас ещё остались неучтёнными отзывы сомелье! Непорядок."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* токенизируем\n",
    "* нормализируем ([стемминг и/или лемматизация](https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html))\n",
    "\n",
    "Для работы лемматизации английского текста можно воспользоваться библиотекой [SpaCy]( https://spacy.io/). Также, для работы с текстом удобно использовать библиотеку nltk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/Jeniamakarchik/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/Jeniamakarchik/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/Jeniamakarchik/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import word_tokenize, pos_tag_sents, pos_tag\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "def is_noun(tag):\n",
    "    return tag in ['NN', 'NNS', 'NNP', 'NNPS']\n",
    "\n",
    "\n",
    "def is_verb(tag):\n",
    "    return tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
    "\n",
    "\n",
    "def is_adverb(tag):\n",
    "    return tag in ['RB', 'RBR', 'RBS']\n",
    "\n",
    "\n",
    "def is_adjective(tag):\n",
    "    return tag in ['JJ', 'JJR', 'JJS']\n",
    "\n",
    "\n",
    "def penn_to_wn(tag):\n",
    "    if is_adjective(tag):\n",
    "        return wn.ADJ\n",
    "    elif is_noun(tag):\n",
    "        return wn.NOUN\n",
    "    elif is_adverb(tag):\n",
    "        return wn.ADV\n",
    "    elif is_verb(tag):\n",
    "        return wn.VERB\n",
    "    return wn.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2cb7c99e444b18938f08d64273ae77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "description_lemma = []\n",
    "lemmer = WordNetLemmatizer()\n",
    "for sent in tqdm(data.description):\n",
    "    words = []\n",
    "    for token, pos in pos_tag(nltk.word_tokenize(sent), lang='eng'):\n",
    "        wn_pos = penn_to_wn(pos)\n",
    "        words.append(lemmer.lemmatize(token, wn_pos))\n",
    "    description_lemma.append(' '.join(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Hint: вам может пригодиться строчка ```sudo python3 -m spacy download en```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38264258d07a47e6809363ecf597b8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=129971), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en')\n",
    "# По-хорошему надо так\n",
    "description_lemma = [' '.join([token.lemma_ for token in nlp(text)]) \n",
    "                     for text in tqdm(data.description)]\n",
    "# description_lemma = [' '.join([token for token in text.split(' ')]) \n",
    "#                      for text in tqdm(data.description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aroma include tropical fruit , broom , brimstone and dry herb . the palate be not overly expressive , offer unripened apple , citrus and dry sage alongside brisk acidity .'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description_lemma[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129971"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_lemma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Ну пусть мы каждое слово привели к нормальной форме. Но как описать текст? Какие фичи посчитать?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bag of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cоздаем вектор длиной в словарь, для каждого слова считаем количество вхождений в текст и подставляем это число на соответствующую позицию в векторе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Построим модель BOW с помощью [CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря:  26922\n",
      "Top-10 слов:  and the be of with pron this wine flavor fruit\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer().fit(description_lemma)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print('Размер словаря: ', len(vocabulary))\n",
    "\n",
    "description_count = vectorizer.transform(description_lemma)\n",
    "top_tokens, _ = zip(*sorted(zip(vocabulary, description_count.sum(axis=0).getA1()), \n",
    "                            key=lambda x: x[1], reverse=True)[:10])\n",
    "print('Top-10 слов: ', ' '.join(top_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Видно, что большая часть из топ-10 слов является не информативными - стоп-словами. Что бы они не участвовали в представление, в конструктор CountVectorizer в качестве параметра можно передать список стоп-слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Jeniamakarchik/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря:  26825\n",
      "Top-10 слов:  pron wine flavor fruit finish aroma palate acidity cherry tannin\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "vectorizer = CountVectorizer(stop_words=stop_words).fit(description_lemma)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print('Размер словаря: ', len(vocabulary))\n",
    "\n",
    "description_count = vectorizer.transform(description_lemma)\n",
    "top_tokens, _ = zip(*sorted(zip(vocabulary, description_count.sum(axis=0).getA1()), \n",
    "                            key=lambda x: x[1], reverse=True)[:10])\n",
    "print('Top-10 слов: ', ' '.join(top_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Чтобы сжать векторное представление, можно \"отбросить\" редкие слова:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 13585\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<129971x13585 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3253123 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words=stop_words, min_df=3).fit(description_lemma)\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "print('Размер словаря: %d'%len(vocabulary))\n",
    "\n",
    "description_count = vectorizer.transform(description_lemma)\n",
    "description_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tf-Idf\n",
    "\n",
    "Cлова, которые редко встречаются в корпусе (во всех рассматриваемых документах этого набора данных), но присутствуют в этом конкретном документе, могут оказаться более важными. Тогда имеет смысл повысить вес более узкотематическим словам, чтобы отделить их от общетематических. Этот подход называется [TF-IDF](https://en.wikipedia.org/wiki/Tf–idf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Значение Tf-Idf для каждого пары документ-слово состоит из двух компонент:\n",
    "* Term frequency — встречаемость слова в документе\n",
    "\n",
    "$$tf(t, d) = \\frac{n_{t, d}}{\\sum_{k\\in d} n_{k,d}}$$\n",
    "\n",
    "* Inverse Document frequency — логарифм обратной доли документов в которых встретилось данное слово\n",
    "\n",
    "$$idf(t, D) = \\log \\frac{ \\mid D \\mid}{\\mid \\{ d_i \\in D \\mid t \\in d_i \\} \\mid}$$\n",
    "\n",
    "* Tf-Idf — кобминация tf и idf\n",
    "\n",
    "$$ TfIdf(t, d, D) = tf(t, d) * idf(t, D)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Задание 1 (0.5 балла)**. Воспользуйтесь [TfidfVectorizer'ом](https://scikit-learn.org/0.20/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) и посчитайте фичи. Выведите топ-10 слов по убыванию TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          term         rank\n",
      "9384      pron  7097.984600\n",
      "13368     wine  5827.117233\n",
      "4759    flavor  4932.304836\n",
      "5057     fruit  4897.980632\n",
      "376    acidity  3560.532001\n",
      "864      aroma  3515.070123\n",
      "4685    finish  3507.807587\n",
      "8604    palate  3359.468855\n",
      "3849     drink  3354.613732\n",
      "2390    cherry  3289.798799\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words=stop_words, min_df=3)\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(description_lemma)\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "cum_sums = X_tfidf.sum(axis=0) # sum frequences through docs\n",
    "\n",
    "# connecting term to its sums frequency\n",
    "data = []\n",
    "for col, term in enumerate(terms):\n",
    "    data.append((term, cum_sums[0,col]))\n",
    "\n",
    "ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "print(ranking.sort_values('rank', ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Но вернёмся в вину!\n",
    "\n",
    "Добавляем к категориальным признакам, признаки извлечённые из описаний сомелье:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7648924016693479\n"
     ]
    }
   ],
   "source": [
    "X = scipy.sparse.hstack([countries, provinces, varieties, description_count])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33)\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, Y_train)\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "print ('Accuracy: ', accuracy_score(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Задание 2 (0.5 балла)**. Воспользуйтесь посчитанными TF-IDF фичами и проверьте, какое качество предсказания будет, если использовать только их."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7402252220745611\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_tfidf, Y, test_size=0.33)\n",
    "\n",
    "lr = LogisticRegression().fit(X_train, Y_train)\n",
    "Y_pred = lr.predict(X_test)\n",
    "\n",
    "print ('Accuracy: ', accuracy_score(Y_pred, Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Довольно часто бывает, что данных очень много и обучаться приходится на выборках, которые не помещаются в память. А также, довольно часто хорошее качество можно получить благодаря простым линейным моделям, при условии, что были хорошо отобраны и сгенерированы признаки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Важным достоинством линейных методов является то, что при обучении можно добиться того, что настройка параметров алгоритма (т.е. этап обновления весов) будет производится каждый раз при добавлении нового обьекта. Данные методы машинного обучения в литературе часто также называют Online Machine Learning. При этом не нужно хранить все обьекты одновременно в памяти теперь просто не нужно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "На сегодняшний день одной из самых известных реализаций таких методов является пакет [Vowpal Wabbit](https://github.com/JohnLangford/vowpal_wabbit):\n",
    "![](https://cdn.dribbble.com/users/261617/screenshots/3146111/vw-dribbble.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Можно обучать только линейные модели. Увеличивать качество методов, можно за счет добавления новых признаков и подгонки функции потерь\n",
    "\n",
    "* Обучающая выборка обрабатывается с помощью стахостического оптимизатора, благодаря чему можно обучаться на выборках, которые не помещаются в память\n",
    "\n",
    "* Можно обрабатывать большое количество признаков за счет их хэширования (так называемый hashing trick), бладаря чему можно обучать модели даже в случаях, когда полный набор весов просто не помещается в памяти\n",
    "\n",
    "* Поддерживается режим активного обучения, при котором обьекты обучающей выборки можно подавать даже с нескольких машин по сети\n",
    "\n",
    "* Обучение может быть распараллелено на несколько машин"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Установка\n",
    "\n",
    "* ```apt-get install vowpal-wabbit```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Формат данных\n",
    "\n",
    "Label [weight] |Namespace Feature ... |Namespace ...\n",
    "\n",
    "* ```Label``` - метка класса для задачи классификации или действительное число для задачи регрессии\n",
    "* ```weight``` - вес объекта, по умолчанию у всех 1\n",
    "* ```Namespace``` - все признаки разбиты на области видимости, может использоваться для раздельного использования или создания квадратичных признаков между областями\n",
    "* ```Feature``` - ```string[:value]``` или ```int[:value]``` строки будут хешированы, числа будут использоваться как индекс в векторе признаков. ```value``` по умолчанию равно $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Параметры"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Hashing trick**\n",
    "\n",
    "Вводится функция $h$, с помощью которой получается индекс для записи значения в вектор признаков объекта.\n",
    "\n",
    "$$h : F \\rightarrow \\{0, \\dots, 2^b - 1\\}$$\n",
    "\n",
    "С помощью ```--b``` можно задавать размер области значений хеш-функции. Чем больше значение ```b```, тем меньше вероятность получить коллизии при хешировании признаков.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Оптимизация**\n",
    "\n",
    "Может использовать ```SGD``` или ```L-BFGS``` (квази-ньютоновский метод второго порядка, подробнее про работу [оптимизации](http://aria42.com/blog/2014/12/understanding-lbfgs))\n",
    "\n",
    "По умолчанию используется ```SGD```. ```L-BFGS``` включается с помощью ```--bfgs```, работает гораздо медленнее и подходит только для выборок небольшого размера. \n",
    "\n",
    "Количество проходов по данным для ```SGD``` задаётся с помощью параметра ```--passes```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Параметры оптимизации**\n",
    "\n",
    "Обновление весов происходит на каждом объекте:\n",
    "<br/>\n",
    "\n",
    "$$w_{t+1} = w_{t} + \\eta_t \\nabla_{w}\\ell(w_{t}, x_{t})$$\n",
    "$$\\eta_t = \\lambda d^k \\left( \\frac{t_0}{t_0 + t} \\right)^p$$\n",
    "\n",
    "где $t$ - номер объекта при обучении, $k$ - номер эпохи. Остальные параметры задаются следующим образом:\n",
    "\n",
    "* $\\lambda$: ```-l```\n",
    "* $d$: ```--decay_learning_rate```\n",
    "* $t_0$: ```--initial_t```\n",
    "* $p$: ```--power_t```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Функция потерь** задаётся через ```--loss_function```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Регуляризация** задаётся через два флага ```--l1``` и ```--l2```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Квадратичные признаки**\n",
    "\n",
    "* ```-q ab``` — создаёт квадратичные признаки, перемножая все признаки из областей видимости, названия которых начинаются на букву a и на букву b\n",
    "* ```--ignore a``` — игнорирует все признаки из области видимости, название которой начинается на букву a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Подбор гиперпараметров**\n",
    "\n",
    "* Инструмент для [подбора гиперпараметров](https://github.com/VowpalWabbit/vowpal_wabbit/wiki/Using-vw-hypersearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Задание 3 (2 балла)**. Давайте попробуем потрогать руками сами! Для начала, преобразуйте данные, которые мы использовали в формат, который принимает VW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def entry_to_vw(feature, feature_name, label=None):\n",
    "    return str(label+1 or '') + ' |' + feature_name + ' ' + ' '.join(re.findall('\\w{3,}', feature.lower())) + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_vw_file(X, y, filename='dataset'):\n",
    "    amount = len(X)\n",
    "    with open(f'{filename}.vw', 'w') as f:\n",
    "        for i in range(amount):\n",
    "            entry = entry_to_vw(X.iloc[i]['description'], 'description', y.iloc[i][0])\n",
    "            f.write(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aroma include tropical fruit , broom , brimsto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this be ripe and fruity , a wine that be smoot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tart and snappy , the flavor of lime flesh and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pineapple rind , lemon pith and orange blossom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>much like the regular bottling from 2012 , thi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description\n",
       "0  aroma include tropical fruit , broom , brimsto...\n",
       "1  this be ripe and fruity , a wine that be smoot...\n",
       "2  tart and snappy , the flavor of lime flesh and...\n",
       "3  pineapple rind , lemon pith and orange blossom...\n",
       "4  much like the regular bottling from 2012 , thi..."
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_text = pd.DataFrame({\"description\": description_lemma})\n",
    "X_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(Y)\n",
    "Y_numb = pd.DataFrame(le.transform(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_text, Y_numb,  stratify=Y_numb, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_to_vw_file(X_train, y_train, 'data.train')\n",
    "dataset_to_vw_file(X_test, y_test, 'data.test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "У вас должно получиться [что-то в духе](https://yadi.sk/d/hUZ52TJxIKU-dw):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 |description this newly release wine sultry and peppery with lip smack wave blackberry and raspberry bold and brood and ultimately delicious full bodied pron find balance between pron velvety texture and spike black pepper and leather\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 1 data.train.vw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "А теперь запустите VW из командной строки! Вам понадобятся следующие опции:\n",
    "* ```-d``` - путь к данным\n",
    "* ```-f``` - путь к месту, куда нужно сохранить модель\n",
    "* ```--loss_function``` - функция потерь (давайте заиспользуем logistic)\n",
    "* ```--oaa``` - для мультиклассовой классификации one-against-all количество классов\n",
    "* ```--passes``` - количество итераций стохастического градиентного спуска (пусть будет 100)\n",
    "* ```-b``` - размер хеш-функции, давайте сделаем 28\n",
    "* добавим опции ```-c``` ```-k``` (для использования кэша)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_regressor = vw_model\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "decay_learning_rate = 1\n",
      "creating cache_file = data.train.vw.cache\n",
      "Reading datafile = data.train.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "0.000000 0.000000            1            1.0        1        1       36\n",
      "0.500000 1.000000            2            2.0        3        1       46\n",
      "0.750000 1.000000            4            4.0        3        1       39\n",
      "0.625000 0.500000            8            8.0        2        3       21\n",
      "0.812500 1.000000           16           16.0        1        2       42\n",
      "0.531250 0.250000           32           32.0        3        3       28\n",
      "0.468750 0.406250           64           64.0        3        3       41\n",
      "0.421875 0.375000          128          128.0        1        1       33\n",
      "0.410156 0.398438          256          256.0        3        3       23\n",
      "0.408203 0.406250          512          512.0        3        3       32\n",
      "0.400391 0.392578         1024         1024.0        1        1       30\n",
      "0.385254 0.370117         2048         2048.0        3        3       45\n",
      "0.358398 0.331543         4096         4096.0        3        3       41\n",
      "0.335938 0.313477         8192         8192.0        3        3       27\n",
      "0.312073 0.288208        16384        16384.0        3        3       49\n",
      "0.296997 0.281921        32768        32768.0        3        3       30\n",
      "0.282684 0.268372        65536        65536.0        3        3       26\n",
      "0.268850 0.268850       131072       131072.0        2        2       26 h\n",
      "0.258918 0.248987       262144       262144.0        1        3       36 h\n",
      "0.253099 0.247279       524288       524288.0        2        3       42 h\n",
      "\n",
      "finished run\n",
      "number of examples per pass = 93579\n",
      "passes used = 8\n",
      "weighted example sum = 748632.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.246225 h\n",
      "total feature number = 26971480\n"
     ]
    }
   ],
   "source": [
    "!vw -d data.train.vw -f vw_model --loss_function logistic --oaa 3 --passes 100 -b 28 -c -k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "А теперь запустим модель на тесте:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* ```-d``` - путь к данным\n",
    "* ```-i``` — путь до готовой модели\n",
    "* ```-t``` — не обучаться, только вернуть предсказания\n",
    "* ```-r``` — путь до файла для записи сырых предсказаний (```-p``` - выдает предсказанные классы)  \n",
    "* ```--quite``` — не выводить никакую информацию в консоль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only testing\n",
      "predictions = predicted_labels.txt\n",
      "raw predictions = predictions.txt\n",
      "Num weight bits = 28\n",
      "learning rate = 0.5\n",
      "initial_t = 0\n",
      "power_t = 0.5\n",
      "using no cache\n",
      "Reading datafile = data.test.vw\n",
      "num sources = 1\n",
      "average  since         example        example  current  current  current\n",
      "loss     last          counter         weight    label  predict features\n",
      "1.000000 1.000000            1            1.0        2        3       33\n",
      "0.500000 0.000000            2            2.0        3        3       30\n",
      "0.750000 1.000000            4            4.0        2        3       31\n",
      "0.375000 0.000000            8            8.0        3        3       34\n",
      "0.312500 0.250000           16           16.0        1        3       59\n",
      "0.218750 0.125000           32           32.0        3        3       34\n",
      "0.187500 0.156250           64           64.0        3        3       43\n",
      "0.226562 0.265625          128          128.0        1        1       28\n",
      "0.234375 0.242188          256          256.0        3        3       41\n",
      "0.248047 0.261719          512          512.0        3        3       32\n",
      "0.250000 0.251953         1024         1024.0        3        3       26\n",
      "0.241699 0.233398         2048         2048.0        1        3       29\n",
      "0.253662 0.265625         4096         4096.0        3        3       22\n",
      "0.249146 0.244629         8192         8192.0        1        1       35\n",
      "0.249634 0.250122        16384        16384.0        3        3       23\n",
      "\n",
      "finished run\n",
      "number of examples = 25995\n",
      "weighted example sum = 25995.000000\n",
      "weighted label sum = 0.000000\n",
      "average loss = 0.249394\n",
      "total feature number = 937200\n"
     ]
    }
   ],
   "source": [
    "!vw -d data.test.vw -i vw_model -t -r predictions.txt -p predicted_labels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "А теперь считаем предсказания и посчитаем качество!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "with open('predicted_labels.txt') as pred_file:\n",
    "    y_pred = [float(label) for label in pred_file.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7506058857472591\n"
     ]
    }
   ],
   "source": [
    "print ('Accuracy: ', accuracy_score(y_test + 1, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Полезные ссылки\n",
    "* https://github.com/VowpalWabbit/vowpal_wabbit - официальный репозиторий VW\n",
    "* https://www.kaggle.com/kashnitsky/vowpal-wabbit-tutorial-blazingly-fast-learning - отличный туториал\n",
    "* https://github.com/VowpalWabbit/vowpal_wabbit/tree/master/python - питонячая обёртка над VW"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
